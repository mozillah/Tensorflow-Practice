{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Exercise_3_Horses_vs_humans_using_Transfer_Learning_Question-FINAL.ipynb","provenance":[],"collapsed_sections":[]},"coursera":{"course_slug":"convolutional-neural-networks-tensorflow","graded_item_id":"csg1x","launcher_item_id":"GpKYz"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"lbFmQdsZs5eW","colab":{}},"source":["# ATTENTION: Please do not alter any of the provided code in the exercise. Only add your own code where indicated\n","# ATTENTION: Please do not add or remove any cells in the exercise. The grader will check specific cells based on the cell position.\n","# ATTENTION: Please use the provided epoch values when training.\n","\n","# Import all the necessary files!\n","import os\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","from tensorflow.keras import Model\n","from os import getcwd"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1xJZ5glPPCRz","colab":{}},"source":["path_inception = f\"{getcwd()}/../tmp2/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n","\n","from tensorflow.keras.applications.inception_v3 import InceptionV3\n","\n","# Create an instance of the inception model from the local pre-trained weights\n","local_weights_file = path_inception\n","\n","pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n","                                include_top = False, # Remove dense layer before CONV layers\n","                                weights = None) # Don't use default weights\n","\n","pre_trained_model.load_weights(local_weights_file)\n","\n","# Make all the layers in the pre-trained model non-trainable\n","for layer in pre_trained_model.layers:\n","  layer.trainable = False\n","\n","# Expected Output is extremely large, but should end with:\n","\n","#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n","#__________________________________________________________________________________________________\n","#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n","#__________________________________________________________________________________________________\n","#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n","#                                                                 activation_276[0][0]             \n","#__________________________________________________________________________________________________\n","#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n","#                                                                 activation_280[0][0]             \n","#__________________________________________________________________________________________________\n","#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n","#__________________________________________________________________________________________________\n","#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n","#                                                                 mixed9_1[0][0]                   \n","#                                                                 concatenate_5[0][0]              \n","#                                                                 activation_281[0][0]             \n","#==================================================================================================\n","#Total params: 21,802,784\n","#Trainable params: 0\n","#Non-trainable params: 21,802,784"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"CFsUlwdfs_wg","colab":{}},"source":["last_layer = pre_trained_model.get_layer('mixed7')\n","print('last layer output shape: ', last_layer.output_shape)\n","last_output = last_layer.output\n","\n","# Expected Output:\n","# ('last layer output shape: ', (None, 7, 7, 768))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-bsWZWp5oMq9","colab":{}},"source":["# Define a Callback class that stops training once accuracy reaches 97.0%\n","class myCallback(tf.keras.callbacks.Callback):\n","  def on_epoch_end(self, epoch, logs={}):\n","    if(logs.get('accuracy')>0.97):\n","      print(\"\\nReached 97.0% accuracy so cancelling training!\")\n","      self.model.stop_training = True\n","\n","      "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BMXb913pbvFg","colab":{}},"source":["from tensorflow.keras.optimizers import RMSprop\n","\n","# Flatten the output layer to 1 dimension\n","x = layers.Flatten()(last_output)\n","# Add a fully connected layer with 1,024 hidden units and ReLU activation\n","x = layers.Dense(1024, activation='relu')(x)\n","# Add a dropout rate of 0.2\n","x = layers.Dropout(0.2)(x)                  \n","# Add a final sigmoid layer for classification\n","x = layers.Dense  (1, activation='sigmoid')(x)           \n","\n","model = Model( pre_trained_model.input, x) \n","\n","model.compile(optimizer = RMSprop(lr=0.0001), \n","              loss = 'binary_crossentropy', \n","              metrics = ['accuracy'])\n","\n","model.summary()\n","\n","# Expected output will be large. Last few lines should be:\n","\n","# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n","#                                                                  activation_251[0][0]             \n","#                                                                  activation_256[0][0]             \n","#                                                                  activation_257[0][0]             \n","# __________________________________________________________________________________________________\n","# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n","# __________________________________________________________________________________________________\n","# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n","# __________________________________________________________________________________________________\n","# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n","# __________________________________________________________________________________________________\n","# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n","# ==================================================================================================\n","# Total params: 47,512,481\n","# Trainable params: 38,537,217\n","# Non-trainable params: 8,975,264\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HrnL_IQ8knWA","colab":{}},"source":["# Get the Horse or Human dataset\n","path_horse_or_human = f\"{getcwd()}/../tmp2/horse-or-human.zip\"\n","# Get the Horse or Human Validation dataset\n","path_validation_horse_or_human = f\"{getcwd()}/../tmp2/validation-horse-or-human.zip\"\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","import os\n","import zipfile\n","import shutil\n","\n","shutil.rmtree('/tmp')\n","local_zip = path_horse_or_human\n","zip_ref = zipfile.ZipFile(local_zip, 'r')\n","zip_ref.extractall('/tmp/training')\n","zip_ref.close()\n","\n","local_zip = path_validation_horse_or_human\n","zip_ref = zipfile.ZipFile(local_zip, 'r')\n","zip_ref.extractall('/tmp/validation')\n","zip_ref.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"y9okX7_ovskI","colab":{}},"source":["# Define our example directories and files\n","train_dir = '/tmp/training'\n","validation_dir = '/tmp/validation'\n","\n","train_horses_dir = os.path.join('/tmp/training/horses')\n","train_humans_dir = os.path.join('/tmp/training/humans')\n","validation_horses_dir = os.path.join('/tmp/validation/horses')\n","validation_humans_dir = os.path.join('/tmp/validation/humans')\n","\n","train_horses_fnames = os.listdir(train_horses_dir)\n","train_humans_fnames = os.listdir(train_humans_dir)\n","validation_horses_fnames = os.listdir(validation_horses_dir)\n","validation_humans_fnames = os.listdir(validation_humans_dir)\n","\n","print(len(train_horses_fnames))\n","print(len(train_humans_fnames))\n","print(len(validation_horses_fnames))\n","print(len(validation_humans_fnames))\n","\n","# Expected Output:\n","# 500\n","# 527\n","# 128\n","# 128"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"O4s8HckqGlnb","colab":{}},"source":["# Add our data-augmentation parameters to ImageDataGenerator\n","train_datagen = ImageDataGenerator(rescale = 1./255.,\n","                                   rotation_range = 40,\n","                                   width_shift_range = 0.2,\n","                                   height_shift_range = 0.2,\n","                                   shear_range = 0.2,\n","                                   zoom_range = 0.2,\n","                                   horizontal_flip = True)\n","\n","# Note that the validation data should not be augmented!\n","test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n","\n","# Flow training images in batches of 20 using train_datagen generator\n","train_generator = train_datagen.flow_from_directory(train_dir,\n","                                                    batch_size = 20,\n","                                                    class_mode = 'binary', \n","                                                    target_size = (150, 150))     \n","\n","# Flow validation images in batches of 20 using test_datagen generator\n","validation_generator =  test_datagen.flow_from_directory( validation_dir,\n","                                                          batch_size  = 20,\n","                                                          class_mode  = 'binary', \n","                                                          target_size = (150, 150))\n","\n","# Expected Output:\n","# Found 1027 images belonging to 2 classes.\n","# Found 256 images belonging to 2 classes."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Blhq2MAUeyGA","colab":{}},"source":["# Run this and see how many epochs it should take before the callback\n","# fires, and stops training at 97% accuracy\n","\n","callbacks = myCallback()\n","history = model.fit_generator(train_generator,\n","                              validation_data = validation_generator,\n","                              steps_per_epoch = 50,\n","                              epochs = 3,\n","                              validation_steps = 12,\n","                              verbose = 1,\n","                              callbacks=[callbacks])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"C2Fp6Se9rKuL","colab":{}},"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = range(len(acc))\n","\n","plt.plot(epochs, acc, 'r', label='Training accuracy')\n","plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n","plt.title('Training and validation accuracy')\n","plt.legend(loc=0)\n","plt.figure()\n","\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jGof5NONLA09","colab_type":"text"},"source":["# Submission Instructions"]},{"cell_type":"code","metadata":{"id":"71oZDJTfLA0-","colab_type":"code","colab":{}},"source":["# Now click the 'Submit Assignment' button above."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J4CoLnLbLA1F","colab_type":"text"},"source":["# When you're done or would like to take a break, please run the two cells below to save your work and close the Notebook. This will free up resources for your fellow learners. "]},{"cell_type":"code","metadata":{"id":"86gJQ-xMLA1G","colab_type":"code","colab":{}},"source":["%%javascript\n","<!-- Save the notebook -->\n","IPython.notebook.save_checkpoint();"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8lJAkF6CLA1L","colab_type":"code","colab":{}},"source":["%%javascript\n","IPython.notebook.session.delete();\n","window.onbeforeunload = null\n","setTimeout(function() { window.close(); }, 1000);"],"execution_count":0,"outputs":[]}]}